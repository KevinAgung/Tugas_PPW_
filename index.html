<!DOCTYPE html>
<html lang="id">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Kumpulan Tugas</title>
  <link rel="stylesheet" href="style.css">

  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet"/>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

  <style>
    .content { display: none; }
    .content.active { display: block; }
  </style>
</head>
<body>
  <!-- Sidebar -->
  <div class="sidebar">
    <img src="profil.jpg" alt="Foto Profil">
    <h2>Kevin Agung J Mahendra</h2>
    <h2>200411100085</h2>
    <ul>
      <li><a href="#" onclick="showContent('tugas2')">Crawling PTA</a></li>
      <li><a href="#" onclick="showContent('tugas3')">Crawling Berita Online</a></li>
      <li><a href="#" onclick="showContent('tugas4')">Preprocessing PTA</a></li>
      <li><a href="#" onclick="showContent('tugas5')">Preprocessing Berita Online</a></li>
      <li><a href="#" onclick="showContent('tugas6')">TF-IDF & Word Embedding</a></li>
    </ul>
  </div>

  <!-- Main Content -->
  <div class="main">
    <!-- Tugas 2 -->
    <div id="tugas2" class="content active">
      <h1>Crawling PTA</h1>
      <div class="code-box">
<pre><code class="language-python">
import requests as req
from bs4 import BeautifulSoup as bs
import csv
import pandas as pd
hades = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'}
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
def scrape_TA(page):
  global hades
  data=[]
  for p in range(1,page+1):
    if p==1 :
      URL = "https://pta.trunojoyo.ac.id/c_search/byprod/10/"
    else :
      URL = f"https://pta.trunojoyo.ac.id/c_search/byprod/10/{p}"
    request = req.get(URL,hades).text
    soup = bs(request, 'lxml')
    prodi = soup.find_all('div',{'id':'begin'})
    for pro in prodi:
      prod = pro.find('h2').text
    jur = prod[-18:]
    ul = soup.find('ul', 'items list_style')
    li = ul.find_all('li', {'data-id':'id-1'})
    for x in li:
      link = x.find('a','gray button')['href']
      request2 = req.get(link, hades).text
      soup2 = bs(request2, 'lxml')
      abst= soup2.find('p',{'align':'justify'}).text.replace('\r','').replace('\n','')
      main_div = soup2.find('div', style=lambda s: s and 'margin: 15px' in s)
      abstrak_id = ""
      abstrak_en = ""
      if main_div:
          b_tags = main_div.find_all('b')
          for b in b_tags:
              text = b.text.strip().lower()
              if "abstraksi" in text:
                  p_tag = b.find_next('p')
                  abstrak_id = p_tag.text.strip() if p_tag else ""
              elif "abstraction" in text:
                  p_tag = b.find_next('p')
                  abstrak_en = p_tag.text.strip() if p_tag else ""
      NPM = x.find('a','gray button')['href'][-12:]
      headline = x.find('a', 'title').text.replace('\r','').replace('\n','')
      pembimbing_pertama = x.select_one('span:contains("Dosen Pembimbing I")').text.split(' : ')[1]
      pembimbing_kedua = x.select_one('span:contains("Dosen Pembimbing II")').text.split(' :')[1]
      data.append([NPM,pembimbing_pertama,pembimbing_kedua,headline,abstrak_id,abstrak_en,jur])
      print([NPM,pembimbing_pertama,pembimbing_kedua,headline,abstrak_id,abstrak_en,jur])

  return data
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
data_TA=scrape_TA(2)
data_TA_result=pd.DataFrame(data_TA)
data_TA_result.columns = ["NPM","Pembimbing Pertama","Pembimbing Kedua","Judul","Abstrak","Abstraction","jurusan"]
data_TA_result
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
data_TA_result.to_csv('data_scrap_PTA.csv')
data_TA_result.to_excel('data_scrap_PTA.xlsx', index=False)
</code></pre>
      </div>
    </div>

    <!-- Tugas 3 -->
    <div id="tugas3" class="content">
      <h1>Crawling Berita Online</h1>
      <div class="code-box">
<pre><code class="language-python">
import requests as req
from bs4 import BeautifulSoup as bs
import csv
import pandas as pd
hades = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
from bs4 import BeautifulSoup as bs
import requests as req

def scrape_detik(page):
    global hades  # header atau session request
    data = []

    for p in range(1, page + 1):
        print(f"Scraping page {p} ...")
        url = f"https://www.detik.com/search/searchall?query=puan+maharani&siteid=2&sortby=time&page={p}"
        request = req.get(url, hades).text

        soup = bs(request, 'lxml')
        news_list = soup.find('div', class_='list-content')

        if news_list is None:
            print(f"Page {p}: div list-content tidak ditemukan")
            continue

        news_article = news_list.find_all('article')
        for x in news_article:
            # ambil judul
            title_tag = x.find('h3', class_='media__title')
            title = title_tag.text.strip() if title_tag else ""

            # ambil deskripsi
            desc_tag = x.find('div', class_='media__desc')
            desc = desc_tag.text.strip() if desc_tag else ""

            data.append([title, desc])

    return data

</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
news=scrape_detik(50)
news_result=pd.DataFrame(news)
news_result.columns = ["Judul", "Konten"]
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
news_result.to_csv('berita.csv',index=False)
news_result.to_excel('berita.xlsx', index=False)
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
import pandas as pd
#read in the data using pandas
url = pd.read_csv('/content/berita.csv')
url.head(50)
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
data_TA_result.to_csv('data_scrap_PTA.csv')
data_TA_result.to_excel('data_scrap_PTA.xlsx', index=False)
</code></pre>
      </div>

    </div>

    <!-- Tugas 4 -->
    <div id="tugas4" class="content">
      <h1>Preprocessing PTA</h1>
      <div class="code-box">
<pre><code class="language-python">
import requests as req
from bs4 import BeautifulSoup as bs
import csv
import pandas as pd
hades = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'}
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
def scrape_TA(page):
  global hades
  data=[]
  for p in range(1,page+1):
    if p==1 :
      URL = "https://pta.trunojoyo.ac.id/c_search/byprod/10/"
    else :
      URL = f"https://pta.trunojoyo.ac.id/c_search/byprod/10/{p}"
    request = req.get(URL,hades).text
    #var bs yang menyimpan data request berupa html
    soup = bs(request, 'lxml')
    prodi = soup.find_all('div',{'id':'begin'})
    for pro in prodi:
      prod = pro.find('h2').text
    jur = prod[-18:]
    ul = soup.find('ul', 'items list_style')
    li = ul.find_all('li', {'data-id':'id-1'})
    for x in li:
      link = x.find('a','gray button')['href']
      request2 = req.get(link, hades).text
      soup2 = bs(request2, 'lxml')
      abst= soup2.find('p',{'align':'justify'}).text.replace('\r','').replace('\n','')
      # ambil abstrak ID dan EN
      main_div = soup2.find('div', style=lambda s: s and 'margin: 15px' in s)
      abstrak_id = ""
      abstrak_en = ""
      if main_div:
          b_tags = main_div.find_all('b')
          for b in b_tags:
              text = b.text.strip().lower()
              if "abstraksi" in text:
                  p_tag = b.find_next('p')
                  abstrak_id = p_tag.text.strip() if p_tag else ""
              elif "abstraction" in text:
                  p_tag = b.find_next('p')
                  abstrak_en = p_tag.text.strip() if p_tag else ""
      NPM = x.find('a','gray button')['href'][-12:]
      headline = x.find('a', 'title').text.replace('\r','').replace('\n','')
      pembimbing_pertama = x.select_one('span:contains("Dosen Pembimbing I")').text.split(' : ')[1]
      pembimbing_kedua = x.select_one('span:contains("Dosen Pembimbing II")').text.split(' :')[1]
      data.append([NPM,pembimbing_pertama,pembimbing_kedua,headline,abstrak_id,abstrak_en,jur])
      print([NPM,pembimbing_pertama,pembimbing_kedua,headline,abstrak_id,abstrak_en,jur])

  return data
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
data_TA=scrape_TA(2)
# data_TA=scrape_TA(172)
data_TA_result=pd.DataFrame(data_TA)
data_TA_result.columns = ["NPM","Pembimbing Pertama","Pembimbing Kedua","Judul","Abstrak","Abstraction","jurusan"]
data_TA_result
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
!pip install Sastrawi
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
import requests as req
from bs4 import BeautifulSoup as bs
import pandas as pd
import re, string

import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('punkt_tab')


from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
factory = StemmerFactory()
stemmer = factory.create_stemmer()
</code></pre>
      </div>

      <div class="code-box">
<pre><code class="language-python">
import re
import string
from bs4 import BeautifulSoup
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from nltk.tokenize import word_tokenize

# Buat stemmer & stopword remover
stemmer = StemmerFactory().create_stemmer()
stopword = StopWordRemoverFactory().create_stop_word_remover()

# Fungsi cleaning
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()  # huruf kecil
    text = re.sub(r'\d+', '', text)  # hapus angka
    text = text.translate(str.maketrans('', '', string.punctuation))  # hapus tanda baca
    text = re.sub(r'\s+', ' ', text)  # rapikan spasi
    text = BeautifulSoup(text, "html.parser").get_text()  # hapus tag HTML
    return text.strip()

# 1. Cleaning abstrak
data_TA_result["clean_text"] = data_TA_result["Abstrak"].apply(clean_text)

# 2. Hapus stopword
data_TA_result["no_stopword"] = data_TA_result["clean_text"].apply(lambda x: stopword.remove(x))

# 3. Stemming (langsung kalimat penuh)
data_TA_result["Abstrak_Stem"] = data_TA_result["no_stopword"].apply(lambda x: stemmer.stem(x))

# 4. Tokenisasi setelah stemming
data_TA_result["Abstrak_Token"] = data_TA_result["Abstrak_Stem"].apply(lambda x: word_tokenize(x))

# Tampilkan hasil
print(data_TA_result[["Judul","Abstrak","clean_text","no_stopword","Abstrak_Stem","Abstrak_Token"]].head())
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
data_TA_result.to_csv('hasil_preprocessing.csv')
data_TA_result.to_excel('hasil_preprocessing.xlsx', index=False)
</code></pre>
      </div>
    </div>

    <!-- Tugas 5 -->
    <div id="tugas5" class="content">
      <h1>Preprocessing Berita Online</h1>
      <div class="code-box">
<pre><code class="language-python">
import requests as req
from bs4 import BeautifulSoup as bs
import csv
import pandas as pd
hades = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
from bs4 import BeautifulSoup as bs
import requests as req

def scrape_detik(page):
    global hades
    data = []

    for p in range(1, page + 1):
        print(f"Scraping page {p} ...")
        url = f"https://www.detik.com/search/searchall?query=puan+maharani&siteid=2&sortby=time&page={p}"
        request = req.get(url, hades).text

        soup = bs(request, 'lxml')
        news_list = soup.find('div', class_='list-content')

        if news_list is None:
            print(f"Page {p}: div list-content tidak ditemukan")
            continue

        news_article = news_list.find_all('article')
        for x in news_article:
            # ambil judul
            title_tag = x.find('h3', class_='media__title')
            title = title_tag.text.strip() if title_tag else ""

            # ambil deskripsi
            desc_tag = x.find('div', class_='media__desc')
            desc = desc_tag.text.strip() if desc_tag else ""

            data.append([title, desc])

    return data
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
news=scrape_detik(50)
news_result=pd.DataFrame(news)
news_result.columns = ["Judul", "Konten"]
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
news_result.to_csv('berita.csv',index=False)
news_result.to_excel('berita.xlsx', index=False)
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
import pandas as pd
#read in the data using pandas
url = pd.read_csv('/content/berita.csv')
url.head(50)
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
!pip install Sastrawi
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
import requests as req
from bs4 import BeautifulSoup as bs
import pandas as pd
import re, string

import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('punkt_tab')


from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
factory = StemmerFactory()
stemmer = factory.create_stemmer()
</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
import re
import string
from bs4 import BeautifulSoup
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from nltk.tokenize import word_tokenize

# Buat stemmer & stopword remover
stemmer = StemmerFactory().create_stemmer()
stopword = StopWordRemoverFactory().create_stop_word_remover()

# Fungsi cleaning
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()  # huruf kecil
    text = re.sub(r'\d+', '', text)  # hapus angka
    text = text.translate(str.maketrans('', '', string.punctuation))  # hapus tanda baca
    text = re.sub(r'\s+', ' ', text)  # hapus spasi berlebih
    text = BeautifulSoup(text, "html.parser").get_text()  # hapus tag HTML
    return text.strip()

# 1. Cleaning
news_result["clean_text"] = news_result["Konten"].apply(clean_text)

# 2. Hapus stopword
news_result["no_stopword"] = news_result["clean_text"].apply(lambda x: stopword.remove(x))

# 3. Stemming (langsung ke teks penuh)
news_result["news_Stem"] = news_result["no_stopword"].apply(lambda x: stemmer.stem(x))

# 4. Tokenisasi setelah stemming
news_result["news_Token"] = news_result["news_Stem"].apply(lambda x: word_tokenize(x))

# Tampilkan hasil
print(news_result[["Judul","Konten","clean_text","no_stopword","news_Stem","news_Token"]].head())

</code></pre>
      </div>

       <div class="code-box">
<pre><code class="language-python">
news_result.to_csv('hasil_preprocessingg_berita.csv')
news_result.to_excel('hasil_preprocessingg_berita.xlsx', index=False)
</code></pre>
      </div>
    </div>
  </div>

  <!-- Script untuk switch konten -->
  <script>
    function showContent(id) {
      const contents = document.querySelectorAll('.content');
      contents.forEach(c => c.classList.remove('active'));
      document.getElementById(id).classList.add('active');
    }
  </script>
</body>
</html>
